{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 \n",
    "## Niall Buckley\n",
    "## 115571753"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "from sklearn.feature_extraction import stop_words\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names, dtype=None):\n",
    "        self.attribute_names = attribute_names\n",
    "        self.dtype = dtype\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_selected = X[self.attribute_names]\n",
    "        if self.dtype:\n",
    "            return X_selected.astype(self.dtype).values\n",
    "        return X_selected.values\n",
    "\n",
    "class FeatureBinarizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, features_values):\n",
    "        self.features_values = features_values\n",
    "        self.num_features = len(features_values)\n",
    "        self.labelencodings = [LabelEncoder().fit(feature_values) for feature_values in features_values]\n",
    "        self.onehotencoder = OneHotEncoder(sparse=False,\n",
    "            n_values=[len(feature_values) for feature_values in features_values])\n",
    "        self.last_indexes = np.cumsum([len(feature_values) - 1 for feature_values in self.features_values])\n",
    "    def fit(self, X, y=None):\n",
    "        for i in range(0, self.num_features):\n",
    "            X[:, i] = self.labelencodings[i].transform(X[:, i])\n",
    "        return self.onehotencoder.fit(X)\n",
    "    def transform(self, X, y=None):\n",
    "        for i in range(0, self.num_features):\n",
    "            X[:, i] = self.labelencodings[i].transform(X[:, i])\n",
    "        onehotencoded = self.onehotencoder.transform(X)\n",
    "        return np.delete(onehotencoded, self.last_indexes, axis=1)\n",
    "    def fit_transform(self, X, y=None):\n",
    "        onehotencoded = self.fit(X).transform(X)\n",
    "        return np.delete(onehotencoded, self.last_indexes, axis=1)\n",
    "    def get_params(self, deep=True):\n",
    "        return {\"features_values\" : self.features_values}\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            self.setattr(parameter, value)\n",
    "        return self\n",
    "    \n",
    "class MissingValueImputer(Imputer):\n",
    "    def __init__(self, **kwargs):\n",
    "        Imputer.__init__(self, **kwargs)\n",
    "    def fit(self, X, y=None):\n",
    "        if self.strategy == \"most_frequent\":\n",
    "            self.fills = pd.DataFrame(X).mode(axis=0).squeeze() \n",
    "            return self\n",
    "        else:\n",
    "            return Imputer.fit(self, X, y=y)\n",
    "    def transform(self, X):\n",
    "        if hasattr(self, \"fills\"):\n",
    "            return pd.DataFrame(X).fillna(self.fills).values\n",
    "        else:\n",
    "            return Imputer.transform(self, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset_statements.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle\n",
    "df = df.take(np.random.permutation(len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12791, 14)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                    int64\n",
       "label                object\n",
       "statement            object\n",
       "subject              object\n",
       "speaker              object\n",
       "job                  object\n",
       "state                object\n",
       "party                object\n",
       "num_barely_trues    float64\n",
       "num_falses          float64\n",
       "num_half_trues      float64\n",
       "num_mostly_trues    float64\n",
       "num_pants_fires     float64\n",
       "location             object\n",
       "dtype: object"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'label', 'statement', 'subject', 'speaker', 'job', 'state',\n",
       "       'party', 'num_barely_trues', 'num_falses', 'num_half_trues',\n",
       "       'num_mostly_trues', 'num_pants_fires', 'location'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "3567\n",
      "2749\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "131\n"
     ]
    }
   ],
   "source": [
    "for cols in df.columns:\n",
    "    print(df[cols].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>statement</th>\n",
       "      <th>subject</th>\n",
       "      <th>speaker</th>\n",
       "      <th>job</th>\n",
       "      <th>state</th>\n",
       "      <th>party</th>\n",
       "      <th>num_barely_trues</th>\n",
       "      <th>num_falses</th>\n",
       "      <th>num_half_trues</th>\n",
       "      <th>num_mostly_trues</th>\n",
       "      <th>num_pants_fires</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12791.000000</td>\n",
       "      <td>12791</td>\n",
       "      <td>12791</td>\n",
       "      <td>12789</td>\n",
       "      <td>12789</td>\n",
       "      <td>9224</td>\n",
       "      <td>10042</td>\n",
       "      <td>12789</td>\n",
       "      <td>12789.000000</td>\n",
       "      <td>12789.000000</td>\n",
       "      <td>12789.000000</td>\n",
       "      <td>12789.000000</td>\n",
       "      <td>12789.000000</td>\n",
       "      <td>12660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>12765</td>\n",
       "      <td>4534</td>\n",
       "      <td>3309</td>\n",
       "      <td>1355</td>\n",
       "      <td>85</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>half-true</td>\n",
       "      <td>On changing the rules for filibusters on presi...</td>\n",
       "      <td>health-care</td>\n",
       "      <td>barack-obama</td>\n",
       "      <td>President</td>\n",
       "      <td>Texas</td>\n",
       "      <td>republican</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a news release</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2627</td>\n",
       "      <td>3</td>\n",
       "      <td>474</td>\n",
       "      <td>611</td>\n",
       "      <td>615</td>\n",
       "      <td>1260</td>\n",
       "      <td>5665</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6773.300211</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.583939</td>\n",
       "      <td>13.359059</td>\n",
       "      <td>17.185785</td>\n",
       "      <td>16.497850</td>\n",
       "      <td>6.251388</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3906.695086</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.978037</td>\n",
       "      <td>24.140086</td>\n",
       "      <td>35.847678</td>\n",
       "      <td>36.165276</td>\n",
       "      <td>16.180777</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3368.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6818.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10145.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>13531.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>163.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id      label  \\\n",
       "count   12791.000000      12791   \n",
       "unique           NaN          6   \n",
       "top              NaN  half-true   \n",
       "freq             NaN       2627   \n",
       "mean     6773.300211        NaN   \n",
       "std      3906.695086        NaN   \n",
       "min         1.000000        NaN   \n",
       "25%      3368.500000        NaN   \n",
       "50%      6818.000000        NaN   \n",
       "75%     10145.500000        NaN   \n",
       "max     13531.000000        NaN   \n",
       "\n",
       "                                                statement      subject  \\\n",
       "count                                               12791        12789   \n",
       "unique                                              12765         4534   \n",
       "top     On changing the rules for filibusters on presi...  health-care   \n",
       "freq                                                    3          474   \n",
       "mean                                                  NaN          NaN   \n",
       "std                                                   NaN          NaN   \n",
       "min                                                   NaN          NaN   \n",
       "25%                                                   NaN          NaN   \n",
       "50%                                                   NaN          NaN   \n",
       "75%                                                   NaN          NaN   \n",
       "max                                                   NaN          NaN   \n",
       "\n",
       "             speaker        job  state       party  num_barely_trues  \\\n",
       "count          12789       9224  10042       12789      12789.000000   \n",
       "unique          3309       1355     85          24               NaN   \n",
       "top     barack-obama  President  Texas  republican               NaN   \n",
       "freq             611        615   1260        5665               NaN   \n",
       "mean             NaN        NaN    NaN         NaN         11.583939   \n",
       "std              NaN        NaN    NaN         NaN         18.978037   \n",
       "min              NaN        NaN    NaN         NaN          0.000000   \n",
       "25%              NaN        NaN    NaN         NaN          0.000000   \n",
       "50%              NaN        NaN    NaN         NaN          2.000000   \n",
       "75%              NaN        NaN    NaN         NaN         12.000000   \n",
       "max              NaN        NaN    NaN         NaN         70.000000   \n",
       "\n",
       "          num_falses  num_half_trues  num_mostly_trues  num_pants_fires  \\\n",
       "count   12789.000000    12789.000000      12789.000000     12789.000000   \n",
       "unique           NaN             NaN               NaN              NaN   \n",
       "top              NaN             NaN               NaN              NaN   \n",
       "freq             NaN             NaN               NaN              NaN   \n",
       "mean       13.359059       17.185785         16.497850         6.251388   \n",
       "std        24.140086       35.847678         36.165276        16.180777   \n",
       "min         0.000000        0.000000          0.000000         0.000000   \n",
       "25%         0.000000        0.000000          0.000000         0.000000   \n",
       "50%         2.000000        3.000000          3.000000         1.000000   \n",
       "75%        15.000000       13.000000         12.000000         5.000000   \n",
       "max       114.000000      160.000000        163.000000       105.000000   \n",
       "\n",
       "              location  \n",
       "count            12660  \n",
       "unique            5142  \n",
       "top     a news release  \n",
       "freq               309  \n",
       "mean               NaN  \n",
       "std                NaN  \n",
       "min                NaN  \n",
       "25%                NaN  \n",
       "50%                NaN  \n",
       "75%                NaN  \n",
       "max                NaN  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include= \"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the dataet\n",
    "#### I will try to keep as much useful information from the dataset as possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ID will not be necessary for this project as it's not very informative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('id', axis=1, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### clean speaker column\n",
    "speaker column looks a little strange <br>\n",
    "President frequecy = 615, yet obama only appears in dataset 611 times <br>\n",
    "were 3 speakers incorrectly labelled president?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[(df['job'] == 'President') & (df['speaker'] != 'barack-obama')].copy()\n",
    "x['speaker']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 3 non obama speakers were George-Bush which makes sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### clean subject column\n",
    "It looks O.K. from the describe except the count for speaker does not match the dataset count seen in shape\n",
    "Lets see if it has any nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>statement</th>\n",
       "      <th>subject</th>\n",
       "      <th>speaker</th>\n",
       "      <th>job</th>\n",
       "      <th>state</th>\n",
       "      <th>party</th>\n",
       "      <th>num_barely_trues</th>\n",
       "      <th>num_falses</th>\n",
       "      <th>num_half_trues</th>\n",
       "      <th>num_mostly_trues</th>\n",
       "      <th>num_pants_fires</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4380</th>\n",
       "      <td>false</td>\n",
       "      <td>Joe, I keep hearing you every morning talking ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7277</th>\n",
       "      <td>false</td>\n",
       "      <td>The fact is that although we have had a presid...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                          statement subject  \\\n",
       "4380  false  Joe, I keep hearing you every morning talking ...     NaN   \n",
       "7277  false  The fact is that although we have had a presid...     NaN   \n",
       "\n",
       "     speaker  job state party  num_barely_trues  num_falses  num_half_trues  \\\n",
       "4380     NaN  NaN   NaN   NaN               NaN         NaN             NaN   \n",
       "7277     NaN  NaN   NaN   NaN               NaN         NaN             NaN   \n",
       "\n",
       "      num_mostly_trues  num_pants_fires location  \n",
       "4380               NaN              NaN      NaN  \n",
       "7277               NaN              NaN      NaN  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Subject only contains two NaNs and the rows are pretty sparse of information\n",
    "#so it can go\n",
    "subject_nans = (df[(df[\"subject\"].isnull() == 1)]).copy()\n",
    "subject_nans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does. It also shows the 2 NaNs shown for other columns too (including party, subject, speaker)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove these as it is so sparse of data it couldn't be used for much anyway"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "subject column contains a lot of useful information but it is too diverse, first sepeate each subject into its own string in an array, now the subject column contains arrays of subject strings. This is not great for getting unique features and trying to find a pattern so we must choose a subject at random (we can't just delete the first one as it's alphabetical). So we get the size of the array and randomly pick a subject from the list to assign to the statement. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=[\"subject\"], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['subject'] = df['subject'].astype(str)\n",
    "df['subject'] = [subs.split(',') for subs in df['subject'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "df['subject'] = [i[randint(0,len(i)-1)] for i in df['subject'].values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still contains a lot of non numeric or alphabetic data <br>\n",
    "Need to get rid of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for lower taken from https://www.programiz.com/python-programming/methods/string/lower\n",
    "df['subject'] = df['subject'].str.lower()\n",
    "df['subject'] = df['subject'].replace(['[^a-zA-Z0-9]+'], [' '], regex=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### clean jobs column <br>\n",
    "it's clearly a dirty feature as only 9224 / 12791 contain information. <br>\n",
    "lets look at these null values <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['democrat', 'republican', 'libertarian', 'none', 'organization',\n",
       "       'independent', 'business-leader', 'newsmaker',\n",
       "       'county-commissioner', 'columnist', 'talk-show-host',\n",
       "       'tea-party-member', 'activist', 'government-body', 'journalist',\n",
       "       'labor-leader', 'state-official'], dtype=object)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_nans = (df[(df[\"job\"].isnull() == 1)]).copy()\n",
    "job_nans['party'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well we can see a lot of the nan jobs are politicians or work in media <br>\n",
    "Lets try reduce the nans by compining the features <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['jobs'] = np.where(df['job'].isnull(), df['party'], df['job'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### clean states column <br>\n",
    "We see from the describe all table that its says there are 85 unique states despite the fact that there are only 50 states in America.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Maryland', 'Georgia', nan, 'Pennsylvania', 'New York',\n",
       "       'Tennessee', 'Nevada', 'Washington, D.C.', 'New Jersey',\n",
       "       'Wisconsin', 'California', 'Massachusetts', 'Illinois',\n",
       "       'Minnesota', 'Alabama', 'Texas', 'Arizona', 'New Hampshire',\n",
       "       'Ohio', 'Delaware', 'Florida', 'Oregon', 'New Mexico', 'Colorado',\n",
       "       'North Carolina', 'Rhode Island', 'Missouri', 'Washington',\n",
       "       'Washington, D.C. ', 'Iowa', 'Arkansas', 'Virginia', 'Connecticut',\n",
       "       'Vermont', 'Alaska', 'Kentucky', 'Kansas', 'Louisiana',\n",
       "       'South Carolina', 'Indiana', 'Michigan', 'California ', 'Qatar',\n",
       "       'Georgia ', 'District of Columbia', 'Utah', 'West Virginia',\n",
       "       'Virginia ', 'Montana', 'Virgiia', 'Colorado ', 'Wisconsin ',\n",
       "       'Tennesse', 'Massachusetts ', 'Mississippi', 'None', 'Oregon ',\n",
       "       'South Dakota', 'Oklahoma', 'Maine', 'Atlanta', 'Washington state',\n",
       "       'Virgina', 'Nebraska', 'Unknown', 'ohio', 'Wyoming', 'Florida ',\n",
       "       'Rhode Island ', 'Idaho', 'United Kingdom', 'Illinois ', 'China',\n",
       "       'North Dakota', 'Georgia  ', 'Washington DC', 'the United States',\n",
       "       'New York ', 'Washington D.C.', 'Russia',\n",
       "       'Virginia director, Coalition to Stop Gun Violence',\n",
       "       'Rhode island', 'Tex', 'Hawaii', 'New Hampshire ',\n",
       "       'PA - Pennsylvania'], dtype=object)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"state\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of state information was mistyped or entered incorrectly <br>\n",
    "We will fix it by replacing the incorrectly entered data with better labels<br>\n",
    "It also contains nans nones and unknows which will all become 'none' - I am assuming that these values have some significance, or something in common. <br>\n",
    "The person who created this data set also included countries in the state column I changed this to 'Not America'. <br>\n",
    "Also said Washing DC is a state altough it tecnically, is not.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Maryland', 'Georgia', 'None', 'Pennsylvania', 'Tennessee',\n",
       "       'Nevada', 'Washington DC', 'New Jersey', 'Wisconsin', 'California',\n",
       "       'Massachusetts', 'Illinois', 'Minnesota', 'Alabama', 'Texas',\n",
       "       'Arizona', 'New Hampshire', 'Ohio', 'Delaware', 'Florida',\n",
       "       'Oregon', 'New Mexico', 'Colorado', 'North Carolina',\n",
       "       'Rhode Island', 'Missouri', 'Washington', 'Iowa', 'Arkansas',\n",
       "       'Virginia', 'Connecticut', 'Vermont', 'Alaska', 'Kentucky',\n",
       "       'Kansas', 'Louisiana', 'South Carolina', 'Indiana', 'Michigan',\n",
       "       'Not America', 'Utah', 'West Virginia', 'Montana', 'Tennesse',\n",
       "       'Mississippi', 'South Dakota', 'Oklahoma', 'Maine', 'Atlanta',\n",
       "       'Nebraska', 'Wyoming', 'Idaho', 'North Dakota', 'Hawaii'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['state'].replace(['Virginia ', 'Virginia director, Coalition to Stop Gun Violence', 'Virgiia', 'Virgina'], \"Virginia\", inplace = True)\n",
    "df['state'].replace([['New York '], 'New York'],inplace = True)\n",
    "df['state'].replace(['Washington, D.C.', 'Washington D.C.', 'Washington, D.C. ', 'District of Columbia'],'Washington DC', inplace = True)\n",
    "df['state'].replace(['Georgia ', 'Georgia  '], 'Georgia', inplace = True)\n",
    "df['state'].replace(['Wisconsin '],'Wisconsin', inplace = True)\n",
    "df['state'].replace([np.nan, 'Unknown'], 'None', inplace = True)\n",
    "df['state'].replace(['Washington state'],'Washington', inplace = True)\n",
    "df['state'].replace(['Tex'] , \"Texas\", inplace = True)\n",
    "df['state'].replace([\"PA - Pennsylvania\"], \"Pennsylvania\", inplace = True)\n",
    "df['state'].replace(['Qatar', 'China','Russia', 'United Kingdom'],'Not America', inplace = True)\n",
    "df['state'].replace(['New Hampshire '],'New Hampshire', inplace = True)\n",
    "df['state'].replace(['ohio'],'Ohio', inplace = True)\n",
    "df['state'].replace(['California '],'California', inplace = True)\n",
    "df['state'].replace(['Oregon '],'Oregon', inplace = True)\n",
    "df['state'].replace(['Illinois '],'Illinois', inplace = True)\n",
    "df['state'].replace(['Massachusetts '],'Massachusetts', inplace = True)\n",
    "df['state'].replace(['Colorado '],'Colorado', inplace = True)\n",
    "df['state'].replace(['Florida '],'Florida', inplace = True)\n",
    "df['state'].replace(['Rhode island', 'Rhode Island '],'Rhode Island', inplace = True)\n",
    "df['state'].replace(['the United States'],df['state'].mode(), inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are party values O.K?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12789"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['party'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['democrat', 'none', 'republican', 'libertarian', 'activist',\n",
       "       'organization', 'independent', 'state-official', 'talk-show-host',\n",
       "       'journalist', 'newsmaker', 'business-leader', 'columnist',\n",
       "       'liberal-party-canada', 'county-commissioner', 'labor-leader',\n",
       "       'green', 'democratic-farmer-labor', 'education-official',\n",
       "       'tea-party-member', 'constitution-party', 'government-body',\n",
       "       'Moderate', 'ocean-state-tea-party-action'], dtype=object)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['party'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good, uses term party loosely but that's ok with me"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Location <br>\n",
    "Lets look at the nans now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_nans = (df[(df[\"location\"].isnull() == 1)]).copy()\n",
    "#location_nans['state']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fair to say we can remove them now. <br>\n",
    "A lot of the nans for location have a value in state which could be considered a location so we'll use that so we donn't have to\n",
    "remove too many nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['place'] = np.where(df['location'].isnull(), df['state'], df['location'])\n",
    "#df['place']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Location could also be cleaner if we remove stop words and all non numeric or alphabetic letters from the feature <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/43358857/how-to-remove-special-characters-except-space-from-a-file-in-python\n",
    "#stop = stop_words.ENGLISH_STOP_WORDS\n",
    "stop = stop_words.ENGLISH_STOP_WORDS\n",
    "df.dropna(subset=[\"place\"], inplace=True)\n",
    "df['place'] = df['place'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "df['place'] = df['place'].replace(['[^a-zA-Z0-9]+'], [' '], regex=True)\n",
    "df['place'] = df['place'].apply(lambda x: ' '.join([word for word in x.split() if len(word) > 1]))\n",
    "df.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('job', axis=1, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('location', axis=1, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the predictions <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode the labels\n",
    "y = df[\"label\"].values\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "y_encoded = encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Include various pipelines to run various parameter and strategys to try predict the class the input data belong to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal_features = [\"place\",\"subject\",\"jobs\", \"speaker\", \"party\"]\n",
    "# Create the cross-entropy pipeline\n",
    "pipeline = Pipeline([\n",
    "        (\"selector\", DataFrameSelector(nominal_features)), \n",
    "        #(\"imputer\", MissingValueImputer(missing_values=\"NaN\", strategy=\"most_frequent\")),\n",
    "        (\"binarizer\", FeatureBinarizer([df[feature].unique() for feature in nominal_features])), \n",
    "        (\"estimator\", LogisticRegression(multi_class=\"multinomial\", solver=\"newton-cg\")) \n",
    "    ])\n",
    "\n",
    "nominal_pipeline_with_CCA = Pipeline([\n",
    "        (\"selector\", DataFrameSelector(nominal_features)),\n",
    "        (\"binarizer\", FeatureBinarizer([df[feature].unique() for feature in nominal_features])),\n",
    "        (\"cca\", CCA(n_components=1)),\n",
    "        (\"estimator\", LogisticRegression())\n",
    "    ])\n",
    "\n",
    "# Create the one-versus-rest pipeline\n",
    "ovr_pipeline = Pipeline([\n",
    "        (\"selector\", DataFrameSelector(nominal_features)),\n",
    "        (\"binarizer\", FeatureBinarizer([df[feature].unique() for feature in nominal_features])),\n",
    "        (\"estimator\", LogisticRegression())\n",
    "    ])\n",
    "\n",
    "# Create the classifier\n",
    "maj_pipeline = Pipeline([\n",
    "        (\"selector\", DataFrameSelector(nominal_features)),\n",
    "        (\"binarizer\", FeatureBinarizer([df[feature].unique() for feature in nominal_features])),\n",
    "        (\"estimator\", DummyClassifier(strategy = \"most_frequent\"))\n",
    "    ])\n",
    "strat_pipeline = Pipeline([\n",
    "        (\"selector\", DataFrameSelector(nominal_features)),  \n",
    "        (\"binarizer\", FeatureBinarizer([df[feature].unique() for feature in nominal_features])),\n",
    "        (\"estimator\", DummyClassifier())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Niall\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1639: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Create the object that splits the data\n",
    "ss = ShuffleSplit(n_splits=1, train_size=0.8)\n",
    "ssL = ShuffleSplit(n_splits=1, train_size=0.5)\n",
    "ssH = ShuffleSplit(n_splits=1, train_size=0.90)\n",
    "sss = StratifiedShuffleSplit(n_splits=1, train_size=0.8)\n",
    "kf = KFold(n_splits = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I'm trying to determine what stragety works best to predict the class the input data belongs to. The scoring is a percentage based on how many predictions were correct. <br>\n",
    "I compare my predictions to the dummy classifiers, \n",
    "I imagine that holdout would be better suited to this dataset as it's quite large. And the compution time of k-fold would be unnecessarly huge for a data set of this size<br>\n",
    "**I removed k-fold predictions as computation time was too long.** <br>\n",
    "**I left in my best performing classifiers but you can see I experimented with parameters and methods.** <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-versus-Rest:  0.23377638780297108\n",
      "Majority-class classifier:  0.20541108212461062\n"
     ]
    }
   ],
   "source": [
    "#print(\"Cross entropy using k-fold: \", np.mean(cross_val_score(pipeline, df, y_encoded, scoring=\"accuracy\", cv=10)))\n",
    "print(\"One-versus-Rest: \", np.mean(cross_val_score(ovr_pipeline, df, y_encoded, scoring=\"accuracy\", cv=ss)))\n",
    "print(\"Majority-class classifier: \", np.mean(cross_val_score(maj_pipeline, df, y_encoded, scoring=\"accuracy\", cv=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare with stratified results\n",
    "#print(\"Cross entropy using k-fold: \", np.mean(cross_val_score(pipeline, df, y_encoded, scoring=\"accuracy\", cv=10)))\n",
    "#print(\"Cross entropy with holdout stratified shuffle: \", np.mean(cross_val_score(pipeline, df, y_encoded, scoring=\"accuracy\", cv=sss)))\n",
    "#print(\"Stratified-class classifier: \", np.mean(cross_val_score(strat_pipeline, df, y_encoded, scoring=\"accuracy\", cv=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross entropy multi-class:  0.2509773260359656\n"
     ]
    }
   ],
   "source": [
    "#print(\"Cross entropy using holdout 50% training: \", np.mean(cross_val_score(pipeline, df, y_encoded, scoring=\"accuracy\", cv=ssL)))\n",
    "print(\"cross entropy multi-class: \", np.mean(cross_val_score(pipeline, df, y_encoded, scoring=\"accuracy\", cv=ss)))\n",
    "#print(\"Cross entropy using holdout 90% training: \", np.mean(cross_val_score(pipeline, df, y_encoded, scoring=\"accuracy\", cv=ssH)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifiers perform better than dummy classifiers!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets compare these results compare to how it would have done with minimal data cleaning\n",
    "I will use the classifier that performed best and assume the trend is the same when the dataset is not dirty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset_statements.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.take(np.random.permutation(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('id', axis=1, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>statement</th>\n",
       "      <th>subject</th>\n",
       "      <th>speaker</th>\n",
       "      <th>job</th>\n",
       "      <th>state</th>\n",
       "      <th>party</th>\n",
       "      <th>num_barely_trues</th>\n",
       "      <th>num_falses</th>\n",
       "      <th>num_half_trues</th>\n",
       "      <th>num_mostly_trues</th>\n",
       "      <th>num_pants_fires</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12791</td>\n",
       "      <td>12791</td>\n",
       "      <td>12789</td>\n",
       "      <td>12789</td>\n",
       "      <td>9224</td>\n",
       "      <td>10042</td>\n",
       "      <td>12789</td>\n",
       "      <td>12789.000000</td>\n",
       "      <td>12789.000000</td>\n",
       "      <td>12789.000000</td>\n",
       "      <td>12789.000000</td>\n",
       "      <td>12789.000000</td>\n",
       "      <td>12660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>6</td>\n",
       "      <td>12765</td>\n",
       "      <td>4534</td>\n",
       "      <td>3309</td>\n",
       "      <td>1355</td>\n",
       "      <td>85</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>half-true</td>\n",
       "      <td>On a cap-and-trade plan.</td>\n",
       "      <td>health-care</td>\n",
       "      <td>barack-obama</td>\n",
       "      <td>President</td>\n",
       "      <td>Texas</td>\n",
       "      <td>republican</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a news release</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2627</td>\n",
       "      <td>3</td>\n",
       "      <td>474</td>\n",
       "      <td>611</td>\n",
       "      <td>615</td>\n",
       "      <td>1260</td>\n",
       "      <td>5665</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.583939</td>\n",
       "      <td>13.359059</td>\n",
       "      <td>17.185785</td>\n",
       "      <td>16.497850</td>\n",
       "      <td>6.251388</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.978037</td>\n",
       "      <td>24.140086</td>\n",
       "      <td>35.847678</td>\n",
       "      <td>36.165276</td>\n",
       "      <td>16.180777</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>163.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            label                 statement      subject       speaker  \\\n",
       "count       12791                     12791        12789         12789   \n",
       "unique          6                     12765         4534          3309   \n",
       "top     half-true  On a cap-and-trade plan.  health-care  barack-obama   \n",
       "freq         2627                         3          474           611   \n",
       "mean          NaN                       NaN          NaN           NaN   \n",
       "std           NaN                       NaN          NaN           NaN   \n",
       "min           NaN                       NaN          NaN           NaN   \n",
       "25%           NaN                       NaN          NaN           NaN   \n",
       "50%           NaN                       NaN          NaN           NaN   \n",
       "75%           NaN                       NaN          NaN           NaN   \n",
       "max           NaN                       NaN          NaN           NaN   \n",
       "\n",
       "              job  state       party  num_barely_trues    num_falses  \\\n",
       "count        9224  10042       12789      12789.000000  12789.000000   \n",
       "unique       1355     85          24               NaN           NaN   \n",
       "top     President  Texas  republican               NaN           NaN   \n",
       "freq          615   1260        5665               NaN           NaN   \n",
       "mean          NaN    NaN         NaN         11.583939     13.359059   \n",
       "std           NaN    NaN         NaN         18.978037     24.140086   \n",
       "min           NaN    NaN         NaN          0.000000      0.000000   \n",
       "25%           NaN    NaN         NaN          0.000000      0.000000   \n",
       "50%           NaN    NaN         NaN          2.000000      2.000000   \n",
       "75%           NaN    NaN         NaN         12.000000     15.000000   \n",
       "max           NaN    NaN         NaN         70.000000    114.000000   \n",
       "\n",
       "        num_half_trues  num_mostly_trues  num_pants_fires        location  \n",
       "count     12789.000000      12789.000000     12789.000000           12660  \n",
       "unique             NaN               NaN              NaN            5142  \n",
       "top                NaN               NaN              NaN  a news release  \n",
       "freq               NaN               NaN              NaN             309  \n",
       "mean         17.185785         16.497850         6.251388             NaN  \n",
       "std          35.847678         36.165276        16.180777             NaN  \n",
       "min           0.000000          0.000000         0.000000             NaN  \n",
       "25%           0.000000          0.000000         0.000000             NaN  \n",
       "50%           3.000000          3.000000         1.000000             NaN  \n",
       "75%          13.000000         12.000000         5.000000             NaN  \n",
       "max         160.000000        163.000000       105.000000             NaN  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include= \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=[\"location\"], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeFeaturesStrings(df):\n",
    "    df['location'] = df['location'].astype(str)\n",
    "    df['subject'] = df['subject'].astype(str)\n",
    "    df['speaker'] = df['speaker'].astype(str)\n",
    "    df['party'] = df['party'].astype(str)\n",
    "    df['job'] = df['job'].astype(str)\n",
    "    df['state'] = df['state'].astype(str)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = makeFeaturesStrings(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode the labels\n",
    "y = df[\"label\"].values\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "y_encoded = encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal_features = [\"location\", \"job\", \"party\", \"speaker\", \"subject\"]\n",
    "\n",
    "pipeline = Pipeline([\n",
    "        (\"selector\", DataFrameSelector(nominal_features)), \n",
    "        (\"binarizer\", FeatureBinarizer([df[feature].unique() for feature in nominal_features])), \n",
    "        (\"imputer\", MissingValueImputer(missing_values=\"NaN\", strategy=\"most_frequent\")),\n",
    "        (\"estimator\", LogisticRegression()) \n",
    "])\n",
    "\n",
    "nominal_pipeline_with_CCA = Pipeline([\n",
    "        (\"selector\", DataFrameSelector(nominal_features)),\n",
    "        (\"binarizer\", FeatureBinarizer([df[feature].unique() for feature in nominal_features])),\n",
    "        (\"cca\", CCA(n_components=1)),\n",
    "        (\"estimator\", LogisticRegression())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-versus-Rest:  0.25908372827804105\n"
     ]
    }
   ],
   "source": [
    "print(\"One-versus-Rest: \", np.mean(cross_val_score(pipeline, df, y_encoded, scoring=\"accuracy\", cv=ss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"One-versus-Rest with CCA: \", np.mean(cross_val_score(nominal_pipeline_with_CCA, df, y_encoded, scoring=\"accuracy\", cv=ss)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second classifier works slightly better I was better off not cleaning the data so thoroughly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
